Agente de Aprendizaje por Refuerzo para OptimizaciÃ³n de Camiones Mineros
## 1. DescripciÃ³n General
Este proyecto implementa un agente de aprendizaje por refuerzo (Q-Learning) para optimizar la asignaciÃ³n y despacho de camiones en un entorno minero simulado. El objetivo es reducir tiempos de espera, balancear la carga entre palas, minimizar colas y optimizar el consumo de combustible, utilizando datos reales o sintÃ©ticos del proceso minero.
---

El objetivo principal es:  
- Reducir tiempos de espera  
- Balancear la carga entre palas  
- Minimizar colas   

Se utilizan **datos reales o sintÃ©ticos** del proceso minero como entrada.  

---

## 2. Estructura del Proyecto  

```bash
RL_Agente_Mineria/
â”‚â”€â”€ agent/                  # LÃ³gica principal del agente RL
â”‚   â”œâ”€â”€ q_learning_agent.py # ImplementaciÃ³n del Q-Learning
â”‚   â”œâ”€â”€ state_builder.py    # ConstrucciÃ³n y discretizaciÃ³n de estados
â”‚   â”œâ”€â”€ rewards.py          # FunciÃ³n de recompensa
â”‚   â””â”€â”€ training_agent.py   # Script de entrenamiento
â”‚
â”‚â”€â”€ logs/                   # Carpeta de registros
â”‚   â”œâ”€â”€ decisiones_guardadas/ # Decisiones tomadas por el agente
â”‚   â””â”€â”€ logs_ticks/         # Logs relacionados con los ticks procesados
â”‚
â”‚â”€â”€ notebooks/              # AnÃ¡lisis y visualizaciÃ³n (Jupyter)
â”‚
â”‚â”€â”€ test/                   # Scripts de prueba y validaciÃ³n
â”‚   â”œâ”€â”€ Ejecucion_Agente_RealTime.py
â”‚   â””â”€â”€ Extraer_ticks_Individuales.py
â”‚
â”‚â”€â”€ ticks_filtrados/        # Datos JSON con ticks filtrados
â”‚â”€â”€ utils/                  # Funciones auxiliares
â”‚â”€â”€ config.yaml             # ConfiguraciÃ³n de parÃ¡metros
â”‚â”€â”€ MINE-hudbay-ALGO-2025-08-15.json # Datos de entorno
â”‚â”€â”€ README.md               # DocumentaciÃ³n principal
â”‚â”€â”€ __init__.py             # InicializaciÃ³n de paquetes Python

```

## 3. DescripciÃ³n de Componentes
ğŸ“ agent/

q_learning_agent.py â†’ Clase QLearningAgent que maneja la selecciÃ³n de acciones y actualizaciÃ³n de la Q-table.

state_builder.py â†’ Convierte datos de ticks en estados discretos procesables.

rewards.py â†’ Implementa la funciÃ³n de recompensa, premiando y penalizando segÃºn contexto.

training_agent.py â†’ Orquesta el ciclo de entrenamiento, gestiÃ³n de episodios y persistencia de la Q-table.

ğŸ“ logs/

decisiones_guardadas/ â†’ Decisiones pendientes para el prÃ³ximo tick.

logs_ticks/ â†’ InformaciÃ³n detallada de cada tick procesado.

ğŸ“ notebooks/

ExploraciÃ³n de datos, anÃ¡lisis de rendimiento y visualizaciÃ³n de mÃ©tricas.

ğŸ“ test/

Ejecucion_Agente_RealTime.py â†’ Ejecuta el agente en un entorno simulado o real.

Extraer_ticks_Individuales.py â†’ Analiza ticks especÃ­ficos de forma independiente.

ğŸ“ ticks_filtrados/

Archivos JSON con datos de ticks ya filtrados como entrada.

ğŸ“ utils/

Funciones auxiliares de soporte para distintos scripts.


## 4. Flujo de EjecuciÃ³n

```mermaid
flowchart TB
    A[PreparaciÃ³n de datos<br/>] : Se utilizan archivos JSON de ticks_filtrados como entrada.
                        â†“
    B[ConstrucciÃ³n de estados<br/> state_builder.py] : state_builder.py transforma los datos en estados discretos.
                        â†“
    C[InicializaciÃ³n del agente<br/> q_learning_agent.py] : q_learning_agent.py configura el agente y su Q-table.
                        â†“
    D[DefiniciÃ³n de recompensas<br/> rewards.py] : rewards.py calcula la recompensa para cada acciÃ³n tomada.
                        â†“
    E[Entrenamiento<br/> training_agent.py] : training_agent.py ejecuta el ciclo de aprendizaje, actualizando la Q-table.
                        â†“
    F[EjecuciÃ³n / Pruebas<br/> test/] : Scripts en test permiten ejecutar el agente en tiempo real o analizar resultados.
                        â†“
    G[Logging & anÃ¡lisis<br/> logs/ + notebooks/] : Los resultados y decisiones se almacenan en logs y pueden analizarse con notebooks.
```

![Agente RL](image.png)


## 5. InstalaciÃ³n y Uso
1ï¸âƒ£ Instala las dependencias necesarias (si las hay, por ejemplo, numpy, pandas, etc.).

2ï¸âƒ£ Entrenamiento del agente
python agent/training_agent.py

3ï¸âƒ£ EjecuciÃ³n en tiempo real
python test/Ejecucion_Agente_RealTime.py

## 6. PersonalizaciÃ³n

-- ParÃ¡metros de aprendizaje (alpha, gamma, epsilon) â†’ modificar en q_learning_agent.py.

-- FunciÃ³n de recompensa â†’ ajustar en rewards.py segÃºn objetivos del entorno.

-- DiscretizaciÃ³n de estados â†’ cambiar en state_builder.py para probar representaciones distintas.

## 7. Resultados y MÃ©tricas

Los logs almacenan:

-- Recompensa total

-- NÃºmero de estados Ãºnicos descubiertos

-- Tasa exploraciÃ³n/explotaciÃ³n

-- DistribuciÃ³n de acciones

